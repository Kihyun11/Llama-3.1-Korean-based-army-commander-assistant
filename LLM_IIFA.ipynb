{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495dcca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"sh2orc/Llama-3.1-Korean-8B-Instruct\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "당신은 지휘관의 결심을 돕는 군사 의사결정 보조 AI입니다.\n",
    "\n",
    "역할:\n",
    "- 주어진 전장 상황, 아군 전력 상태, 임무를 토대로 가능한 여러 개의 행동방안(COA)을 제안합니다.\n",
    "- 각 COA에 대해: 의도, 개념(주요 행동), 필요한 전력, 장점, 단점, 주요 위험요인, 전제조건을 정리합니다.\n",
    "- 구체적인 표적/좌표/사격지시 등 \"직접적인 교전 지시\"는 절대 하지 않습니다.\n",
    "- 항상 \"최종 결심은 인간 지휘관이 한다\"는 점을 명확히 합니다.\n",
    "\n",
    "출력 형식:\n",
    "1. 상황 요약\n",
    "2. COA 1\n",
    "3. COA 2\n",
    "4. COA 3\n",
    "5. COA 비교 및 고려사항\n",
    "\n",
    "가능한 한 간결하고 실무적인 한국어로 답변하세요.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def generate_response(tokenizer, model, user_input: str, max_new_tokens: int = 512):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user_input},\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Remove prompt prefix if it appears in the decoded text\n",
    "    if decoded.startswith(prompt):\n",
    "        decoded = decoded[len(prompt):]\n",
    "\n",
    "    return decoded.strip()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tokenizer, model = load_model()\n",
    "\n",
    "    user_input = \"\"\"\n",
    "적 전차 2대와 전투기 1대가 관측되었고, 전체 추정 전력은 약 2개 여단 규모로 평가된다.\n",
    "우리 부대는 기계화 보병대대 1개(전투력 80%), 보병중대 1개(전투력 60%), 대전차 화력은 중간 수준,\n",
    "방공전력은 제한적이다. 상급부대 임무는 '12시간 동안 적의 돌파를 지연하고 전투력을 보존할 것'이다.\n",
    "지형은 개활지와 소규모 구릉이 혼재하며, 우리 후방에는 중요한 교량 1개가 있다.\n",
    "\n",
    "이 상황에서 고려할 수 있는 행동방안(COA)을 제시해 줘.\n",
    "\"\"\".strip()\n",
    "\n",
    "    print(\"=== 지휘관 입력 ===\")\n",
    "    print(user_input)\n",
    "    print(\"\\n=== AI 응답 ===\\n\")\n",
    "    print(generate_response(tokenizer, model, user_input))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
